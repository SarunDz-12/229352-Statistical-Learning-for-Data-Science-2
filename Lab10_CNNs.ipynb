{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SarunDz-12/229352-Statistical-Learning-for-Data-Science-2/blob/main/Lab10_CNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Statistical Learning for Data Science 2 (229352)\n",
        "#### Instructor: Donlapark Ponnoprat\n",
        "\n",
        "#### [Course website](https://donlapark.pages.dev/229352/)\n",
        "\n",
        "## Lab #10"
      ],
      "metadata": {
        "id": "R3EHk_vLhxDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "import torchvision # For utils.make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import zipfile\n",
        "from PIL import Image\n",
        "from tqdm.auto import tqdm # For nice progress bars\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Set device to GPU if available, else CPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "t-jV4RoaQjuy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "855add72-594a-4399-bc0c-00fb33a43225"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use a dataset of pizza, stead and sushi images ([source](https://donlapark.pages.dev/229352/pizza_steak_sushi.zip))"
      ],
      "metadata": {
        "id": "65iWpYjuo1b9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q pizza_steak_sushi.zip"
      ],
      "metadata": {
        "id": "pkoZPKjOcixg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ff92100-e37f-4799-c4ee-93c4f26d1afd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open pizza_steak_sushi.zip, pizza_steak_sushi.zip.zip or pizza_steak_sushi.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data augmentation\n",
        "\n",
        "![augmentation](https://miro.medium.com/max/700/0*LR1ZQucYW96prDte)\n",
        "\n",
        "See more transformations in [Pytorch documentation](https://docs.pytorch.org/vision/stable/transforms.html#v2-api-reference-recommended)"
      ],
      "metadata": {
        "id": "lGMVh81YgMTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# ---------- Device ----------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ---------- Dataset ----------\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    transform=transform,\n",
        "    download=True\n",
        ")\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    transform=transform,\n",
        "    download=True\n",
        ")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "\n",
        "# ---------- CNN Model ----------\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "model = CNN().to(device)\n",
        "\n",
        "# ---------- Loss & Optimizer ----------\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# ---------- Training ----------\n",
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# ---------- Testing ----------\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
      ],
      "metadata": {
        "id": "_CXgPlr4Vt2s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53565576-0177-49a2-d001-b4f57c502eee"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.1586\n",
            "Epoch [2/5], Loss: 0.0457\n",
            "Epoch [3/5], Loss: 0.0325\n",
            "Epoch [4/5], Loss: 0.0243\n",
            "Epoch [5/5], Loss: 0.0176\n",
            "Test Accuracy: 99.03%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Implement and Train LeNet\n",
        "\n",
        "LeNet-5 is one of the earliest convolutional neural networks, developed by Yann LeCun et al. in the 1990s. While originally designed for smaller images (like MNIST digits), we will adapt its architecture for our 224x224 pixel images.\n",
        "\n",
        "![lenet5](http://d2l.ai/_images/lenet.svg)\n",
        "\n",
        "### LeNet Architecture (Adapted for 224x224 input, 3 output classes):\n",
        "\n",
        "1.  **Input Layer**: 3x224x224 image (RGB channels).\n",
        "2.  **Conv1**: ([Conv2d document](https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html))\n",
        "    *   Input Channels: 3\n",
        "    *   Output Channels: 6\n",
        "    *   Kernel Size: 5x5\n",
        "    *   Stride: 1\n",
        "    *   Activation: ReLU\n",
        "3.  **Pool1**: ([MaxPool2d document](https://docs.pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html))\n",
        "    *   Type: Max Pooling\n",
        "    *   Kernel Size: 2x2\n",
        "    *   Stride: 2\n",
        "4.  **Conv2**:\n",
        "    *   Input Channels: 6\n",
        "    *   Output Channels: 16\n",
        "    *   Kernel Size: 5x5\n",
        "    *   Stride: 1\n",
        "    *   Activation: ReLU\n",
        "5.  **Pool2**:\n",
        "    *   Type: Max Pooling\n",
        "    *   Kernel Size: 2x2\n",
        "    *   Stride: 2\n",
        "6.  **Flatten**: Flatten the 3D feature maps into a 1D vector.\n",
        "    *   *Hint*: After Pool2, the feature map size will be `16 * (something) * (something)`. You'll need to calculate this dimension based on the input size and the conv/pool operations.\n",
        "        *   Input (224x224) -> Conv1 (224-5+1 = 220x220)\n",
        "        *   Pool1 (220/2 = 110x110)\n",
        "        *   Conv2 (110-5+1 = 106x106)\n",
        "        *   Pool2 (106/2 = 53x53)\n",
        "        *   So, the output of Pool2 will be `16 * 53 * 53`.\n",
        "7.  **FC1 (Fully Connected 1)**:\n",
        "    *   Input Features: `16 * 53 * 53`\n",
        "    *   Output Features: 120\n",
        "    *   Activation: ReLU\n",
        "8.  **FC2 (Fully Connected 2)**:\n",
        "    *   Input Features: 120\n",
        "    *   Output Features: 84\n",
        "    *   Activation: ReLU\n",
        "9.  **Output Layer (FC3)**:\n",
        "    *   Input Features: 84\n",
        "    *   Output Features: 3 (for pizza, steak, sushi)\n",
        "\n",
        "**Your Task:**\n",
        "1.  Implement the `LeNet` class following the architecture above.\n",
        "2.  Instantiate the model and move it to the `device` (GPU/CPU).\n",
        "3.  Define the loss function (`nn.CrossEntropyLoss`) and optimizer (`optim.Adam`).\n",
        "4.  Train the LeNet model for a few epochs (e.g., 5-10).\n",
        "5.  Evaluate its performance on the test set."
      ],
      "metadata": {
        "id": "mz24H8yLd7Dn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self, num_classes=3):\n",
        "        super(LeNet, self).__init__()\n",
        "\n",
        "        # Conv Layer 1\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=3,\n",
        "            out_channels=6,\n",
        "            kernel_size=5,\n",
        "            stride=1\n",
        "        )\n",
        "\n",
        "        # Pooling\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Conv Layer 2\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels=6,\n",
        "            out_channels=16,\n",
        "            kernel_size=5,\n",
        "            stride=1\n",
        "        )\n",
        "\n",
        "        # Fully Connected Layers\n",
        "        self.fc1 = nn.Linear(16 * 53 * 53, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, num_classes)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "\n",
        "        x = torch.flatten(x, 1)  # flatten\n",
        "\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "es8XVEl5a06G"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model = LeNet(num_classes=3).to(device)\n",
        "\n",
        "lenet_model"
      ],
      "metadata": {
        "id": "Y1pK8roGcYEW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18ab237e-b23f-4499-a406-c6fe61e7a6f0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LeNet(\n",
              "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=44944, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=3, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lenet_model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "PLwJ73BhN_8b"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs):\n",
        "\n",
        "    history = {\"train_loss\": [], \"test_acc\": []}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        # -------- TRAIN --------\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "\n",
        "        # -------- EVAL --------\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images = images.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        acc = correct / total\n",
        "        history[\"test_acc\"].append(acc)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
        "              f\"Loss: {train_loss:.4f} \"\n",
        "              f\"Test Acc: {acc:.4f}\")\n",
        "\n",
        "    return history\n"
      ],
      "metadata": {
        "id": "ok-F447nVwL7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.pool = nn.AvgPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "lenet_model = LeNet()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(lenet_model.parameters(), lr=0.001)\n",
        "\n",
        "print(\"Model parameters OK\")\n"
      ],
      "metadata": {
        "id": "WcSAoCi4oB5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eb41764-95a7-4eec-e103-da0692d61aaa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameters OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self, num_classes=3):\n",
        "        super(LeNet, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "\n",
        "        self.fc1 = nn.Linear(16 * 53 * 53, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, num_classes)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "q_li-wN3lTB8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "id": "pZtinuVXOrs5",
        "outputId": "fe5fd48e-4d84-4df1-de00-1f7a4adc7319",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_model = LeNet(num_classes=3)\n",
        "lenet_model = lenet_model.to(device)\n"
      ],
      "metadata": {
        "id": "gwx_ouMrO6Pa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(next(lenet_model.parameters()).device)\n"
      ],
      "metadata": {
        "id": "jpGqrWqkO9LJ",
        "outputId": "554aac9c-16fe-419c-d9de-911b4015fb93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in train_loader:\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n"
      ],
      "metadata": {
        "id": "RVFDFcuVPC9w"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "lenet_model = LeNet(num_classes=3).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(lenet_model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "NJb1O9lWPa6C"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = images.to(device)\n",
        "labels = labels.to(device)\n"
      ],
      "metadata": {
        "id": "l0mOtI_dPdkX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(LeNet, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, num_classes)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "bf3PsxcePf3O"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "yLn_idBXQBpf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "lenet_model = LeNet().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(lenet_model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "ij2U1TJgQPtu"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet_results = train_model(\n",
        "    lenet_model,\n",
        "    train_loader,\n",
        "    test_loader,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    num_epochs=5\n",
        ")\n"
      ],
      "metadata": {
        "id": "BY2uCf4fQSJ3",
        "outputId": "3ad82e40-66f8-4ef8-d44e-d861661b3979",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5] Loss: 0.2582 Test Acc: 0.9764\n",
            "Epoch [2/5] Loss: 0.0729 Test Acc: 0.9824\n",
            "Epoch [3/5] Loss: 0.0548 Test Acc: 0.9836\n",
            "Epoch [4/5] Loss: 0.0437 Test Acc: 0.9821\n",
            "Epoch [5/5] Loss: 0.0374 Test Acc: 0.9886\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(lenet_results['train_loss'])\n"
      ],
      "metadata": {
        "id": "QViAOlXFQVjx",
        "outputId": "2a060706-988a-48ca-f9dc-5acca9171f93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x78805dc315b0>]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training history\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(lenet_results['train_loss'], label='Train Loss')\n",
        "plt.plot(lenet_results['test_loss'], label='Test Loss')\n",
        "plt.title('LeNet Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(lenet_results['train_acc'], label='Train Accuracy')\n",
        "plt.plot(lenet_results['test_acc'], label='Test Accuracy')\n",
        "plt.title('LeNet Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HSQQpyB_lU-Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "outputId": "2776c038-4550-4a88-8d2b-edb3d9da6f43"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'test_loss'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2651266166.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlenet_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlenet_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Test Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LeNet Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'test_loss'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Final Test Accuracy:\", lenet_results['test_acc'][-1])\n"
      ],
      "metadata": {
        "id": "ybw-EWUgRKyP",
        "outputId": "570fb046-6744-49fd-9dcb-ac86b9d1a86a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Test Accuracy: 0.9886\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Questions for Part 1:\n",
        "1.  How did the LeNet model perform on the test set? What was its final test accuracy?\n",
        "    *   **Your Answer:** = 0.9871"
      ],
      "metadata": {
        "id": "o6CXS-w7ed8o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Transfer Learning\n",
        "\n",
        "Training a deep CNN from scratch can be computationally expensive and requires a large amount of data. Transfer learning is a powerful technique where we take a pre-trained model (trained on a very large dataset like ImageNet) and adapt it for our specific task.\n",
        "\n",
        "Here, we will use `EfficientNet_B0` from `torchvision.models`, which is a powerful and efficient model.\n",
        "\n",
        "[List of pretrained models in Pytorch](https://docs.pytorch.org/vision/main/models.html#classification)\n",
        "\n",
        "**Your Task:**\n",
        "1.  Load a pre-trained `EfficientNet_B0` model.\n",
        "2.  \"Freeze\" the parameters of the feature extractor layers so they are not updated during training.\n",
        "3.  Modify the classifier (head) of the model to output 3 classes (pizza, steak, sushi).\n",
        "    *   *Hint*: For `EfficientNet_B0`, the classifier is typically accessed via `model.classifier`. You'll need to replace its last layer.\n",
        "4.  Instantiate the modified model and move it to the `device`.\n",
        "5.  Define the loss function (`nn.CrossEntropyLoss`) and optimizer.\n",
        "    *   *Important*: Ensure the optimizer *only* updates the parameters of the new, unfrozen layers.\n",
        "6.  Train the transfer learning model for a few epochs (e.g., 5-10).\n",
        "7.  Evaluate its performance on the test set."
      ],
      "metadata": {
        "id": "JpAwzQUBe6Cd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load a pre-trained EfficientNet_B0 model\n",
        "efficientnet_model = models.efficientnet_b0(pretrained=True)"
      ],
      "metadata": {
        "id": "XWeUVDVFmgoU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02294b36-2cfb-4441-b1a0-dfa303f56d47"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "efficientnet_model"
      ],
      "metadata": {
        "id": "tpZj5cBYgfGG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d98c6519-d74d-4276-b166-d346f7739124"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EfficientNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2dNormActivation(\n",
              "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU(inplace=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (2): Conv2dNormActivation(\n",
              "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
              "      )\n",
              "      (2): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
              "      )\n",
              "      (2): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
              "      )\n",
              "      (2): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
              "      )\n",
              "      (3): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (8): Conv2dNormActivation(\n",
              "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.2, inplace=True)\n",
              "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Freeze all parameters in the feature extractor part\n",
        "#### Write your code here\n",
        "\n",
        "\n",
        "# 3 Change the head (the classifier) of the model\n",
        "\n",
        "\n",
        "efficientnet_model = efficientnet_model.to(device)\n",
        "print(\"\\nModified EfficientNet_B0 classifier head:\")\n",
        "print(efficientnet_model.classifier)"
      ],
      "metadata": {
        "id": "Mpycmt3NVy5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6303fe4-e9fe-46dc-c822-dda7be4a71cb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Modified EfficientNet_B0 classifier head:\n",
            "Sequential(\n",
            "  (0): Dropout(p=0.2, inplace=True)\n",
            "  (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check which parameters are being trained\n",
        "print(\"\\nParameters to be trained:\")\n",
        "params_to_update = []\n",
        "for name, param in efficientnet_model.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "        print(name)"
      ],
      "metadata": {
        "id": "-J2h_y-cm8Nr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7551ef4-94d9-44e2-8cbd-5d51b2fae26e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Parameters to be trained:\n",
            "features.0.0.weight\n",
            "features.0.1.weight\n",
            "features.0.1.bias\n",
            "features.1.0.block.0.0.weight\n",
            "features.1.0.block.0.1.weight\n",
            "features.1.0.block.0.1.bias\n",
            "features.1.0.block.1.fc1.weight\n",
            "features.1.0.block.1.fc1.bias\n",
            "features.1.0.block.1.fc2.weight\n",
            "features.1.0.block.1.fc2.bias\n",
            "features.1.0.block.2.0.weight\n",
            "features.1.0.block.2.1.weight\n",
            "features.1.0.block.2.1.bias\n",
            "features.2.0.block.0.0.weight\n",
            "features.2.0.block.0.1.weight\n",
            "features.2.0.block.0.1.bias\n",
            "features.2.0.block.1.0.weight\n",
            "features.2.0.block.1.1.weight\n",
            "features.2.0.block.1.1.bias\n",
            "features.2.0.block.2.fc1.weight\n",
            "features.2.0.block.2.fc1.bias\n",
            "features.2.0.block.2.fc2.weight\n",
            "features.2.0.block.2.fc2.bias\n",
            "features.2.0.block.3.0.weight\n",
            "features.2.0.block.3.1.weight\n",
            "features.2.0.block.3.1.bias\n",
            "features.2.1.block.0.0.weight\n",
            "features.2.1.block.0.1.weight\n",
            "features.2.1.block.0.1.bias\n",
            "features.2.1.block.1.0.weight\n",
            "features.2.1.block.1.1.weight\n",
            "features.2.1.block.1.1.bias\n",
            "features.2.1.block.2.fc1.weight\n",
            "features.2.1.block.2.fc1.bias\n",
            "features.2.1.block.2.fc2.weight\n",
            "features.2.1.block.2.fc2.bias\n",
            "features.2.1.block.3.0.weight\n",
            "features.2.1.block.3.1.weight\n",
            "features.2.1.block.3.1.bias\n",
            "features.3.0.block.0.0.weight\n",
            "features.3.0.block.0.1.weight\n",
            "features.3.0.block.0.1.bias\n",
            "features.3.0.block.1.0.weight\n",
            "features.3.0.block.1.1.weight\n",
            "features.3.0.block.1.1.bias\n",
            "features.3.0.block.2.fc1.weight\n",
            "features.3.0.block.2.fc1.bias\n",
            "features.3.0.block.2.fc2.weight\n",
            "features.3.0.block.2.fc2.bias\n",
            "features.3.0.block.3.0.weight\n",
            "features.3.0.block.3.1.weight\n",
            "features.3.0.block.3.1.bias\n",
            "features.3.1.block.0.0.weight\n",
            "features.3.1.block.0.1.weight\n",
            "features.3.1.block.0.1.bias\n",
            "features.3.1.block.1.0.weight\n",
            "features.3.1.block.1.1.weight\n",
            "features.3.1.block.1.1.bias\n",
            "features.3.1.block.2.fc1.weight\n",
            "features.3.1.block.2.fc1.bias\n",
            "features.3.1.block.2.fc2.weight\n",
            "features.3.1.block.2.fc2.bias\n",
            "features.3.1.block.3.0.weight\n",
            "features.3.1.block.3.1.weight\n",
            "features.3.1.block.3.1.bias\n",
            "features.4.0.block.0.0.weight\n",
            "features.4.0.block.0.1.weight\n",
            "features.4.0.block.0.1.bias\n",
            "features.4.0.block.1.0.weight\n",
            "features.4.0.block.1.1.weight\n",
            "features.4.0.block.1.1.bias\n",
            "features.4.0.block.2.fc1.weight\n",
            "features.4.0.block.2.fc1.bias\n",
            "features.4.0.block.2.fc2.weight\n",
            "features.4.0.block.2.fc2.bias\n",
            "features.4.0.block.3.0.weight\n",
            "features.4.0.block.3.1.weight\n",
            "features.4.0.block.3.1.bias\n",
            "features.4.1.block.0.0.weight\n",
            "features.4.1.block.0.1.weight\n",
            "features.4.1.block.0.1.bias\n",
            "features.4.1.block.1.0.weight\n",
            "features.4.1.block.1.1.weight\n",
            "features.4.1.block.1.1.bias\n",
            "features.4.1.block.2.fc1.weight\n",
            "features.4.1.block.2.fc1.bias\n",
            "features.4.1.block.2.fc2.weight\n",
            "features.4.1.block.2.fc2.bias\n",
            "features.4.1.block.3.0.weight\n",
            "features.4.1.block.3.1.weight\n",
            "features.4.1.block.3.1.bias\n",
            "features.4.2.block.0.0.weight\n",
            "features.4.2.block.0.1.weight\n",
            "features.4.2.block.0.1.bias\n",
            "features.4.2.block.1.0.weight\n",
            "features.4.2.block.1.1.weight\n",
            "features.4.2.block.1.1.bias\n",
            "features.4.2.block.2.fc1.weight\n",
            "features.4.2.block.2.fc1.bias\n",
            "features.4.2.block.2.fc2.weight\n",
            "features.4.2.block.2.fc2.bias\n",
            "features.4.2.block.3.0.weight\n",
            "features.4.2.block.3.1.weight\n",
            "features.4.2.block.3.1.bias\n",
            "features.5.0.block.0.0.weight\n",
            "features.5.0.block.0.1.weight\n",
            "features.5.0.block.0.1.bias\n",
            "features.5.0.block.1.0.weight\n",
            "features.5.0.block.1.1.weight\n",
            "features.5.0.block.1.1.bias\n",
            "features.5.0.block.2.fc1.weight\n",
            "features.5.0.block.2.fc1.bias\n",
            "features.5.0.block.2.fc2.weight\n",
            "features.5.0.block.2.fc2.bias\n",
            "features.5.0.block.3.0.weight\n",
            "features.5.0.block.3.1.weight\n",
            "features.5.0.block.3.1.bias\n",
            "features.5.1.block.0.0.weight\n",
            "features.5.1.block.0.1.weight\n",
            "features.5.1.block.0.1.bias\n",
            "features.5.1.block.1.0.weight\n",
            "features.5.1.block.1.1.weight\n",
            "features.5.1.block.1.1.bias\n",
            "features.5.1.block.2.fc1.weight\n",
            "features.5.1.block.2.fc1.bias\n",
            "features.5.1.block.2.fc2.weight\n",
            "features.5.1.block.2.fc2.bias\n",
            "features.5.1.block.3.0.weight\n",
            "features.5.1.block.3.1.weight\n",
            "features.5.1.block.3.1.bias\n",
            "features.5.2.block.0.0.weight\n",
            "features.5.2.block.0.1.weight\n",
            "features.5.2.block.0.1.bias\n",
            "features.5.2.block.1.0.weight\n",
            "features.5.2.block.1.1.weight\n",
            "features.5.2.block.1.1.bias\n",
            "features.5.2.block.2.fc1.weight\n",
            "features.5.2.block.2.fc1.bias\n",
            "features.5.2.block.2.fc2.weight\n",
            "features.5.2.block.2.fc2.bias\n",
            "features.5.2.block.3.0.weight\n",
            "features.5.2.block.3.1.weight\n",
            "features.5.2.block.3.1.bias\n",
            "features.6.0.block.0.0.weight\n",
            "features.6.0.block.0.1.weight\n",
            "features.6.0.block.0.1.bias\n",
            "features.6.0.block.1.0.weight\n",
            "features.6.0.block.1.1.weight\n",
            "features.6.0.block.1.1.bias\n",
            "features.6.0.block.2.fc1.weight\n",
            "features.6.0.block.2.fc1.bias\n",
            "features.6.0.block.2.fc2.weight\n",
            "features.6.0.block.2.fc2.bias\n",
            "features.6.0.block.3.0.weight\n",
            "features.6.0.block.3.1.weight\n",
            "features.6.0.block.3.1.bias\n",
            "features.6.1.block.0.0.weight\n",
            "features.6.1.block.0.1.weight\n",
            "features.6.1.block.0.1.bias\n",
            "features.6.1.block.1.0.weight\n",
            "features.6.1.block.1.1.weight\n",
            "features.6.1.block.1.1.bias\n",
            "features.6.1.block.2.fc1.weight\n",
            "features.6.1.block.2.fc1.bias\n",
            "features.6.1.block.2.fc2.weight\n",
            "features.6.1.block.2.fc2.bias\n",
            "features.6.1.block.3.0.weight\n",
            "features.6.1.block.3.1.weight\n",
            "features.6.1.block.3.1.bias\n",
            "features.6.2.block.0.0.weight\n",
            "features.6.2.block.0.1.weight\n",
            "features.6.2.block.0.1.bias\n",
            "features.6.2.block.1.0.weight\n",
            "features.6.2.block.1.1.weight\n",
            "features.6.2.block.1.1.bias\n",
            "features.6.2.block.2.fc1.weight\n",
            "features.6.2.block.2.fc1.bias\n",
            "features.6.2.block.2.fc2.weight\n",
            "features.6.2.block.2.fc2.bias\n",
            "features.6.2.block.3.0.weight\n",
            "features.6.2.block.3.1.weight\n",
            "features.6.2.block.3.1.bias\n",
            "features.6.3.block.0.0.weight\n",
            "features.6.3.block.0.1.weight\n",
            "features.6.3.block.0.1.bias\n",
            "features.6.3.block.1.0.weight\n",
            "features.6.3.block.1.1.weight\n",
            "features.6.3.block.1.1.bias\n",
            "features.6.3.block.2.fc1.weight\n",
            "features.6.3.block.2.fc1.bias\n",
            "features.6.3.block.2.fc2.weight\n",
            "features.6.3.block.2.fc2.bias\n",
            "features.6.3.block.3.0.weight\n",
            "features.6.3.block.3.1.weight\n",
            "features.6.3.block.3.1.bias\n",
            "features.7.0.block.0.0.weight\n",
            "features.7.0.block.0.1.weight\n",
            "features.7.0.block.0.1.bias\n",
            "features.7.0.block.1.0.weight\n",
            "features.7.0.block.1.1.weight\n",
            "features.7.0.block.1.1.bias\n",
            "features.7.0.block.2.fc1.weight\n",
            "features.7.0.block.2.fc1.bias\n",
            "features.7.0.block.2.fc2.weight\n",
            "features.7.0.block.2.fc2.bias\n",
            "features.7.0.block.3.0.weight\n",
            "features.7.0.block.3.1.weight\n",
            "features.7.0.block.3.1.bias\n",
            "features.8.0.weight\n",
            "features.8.1.weight\n",
            "features.8.1.bias\n",
            "classifier.1.weight\n",
            "classifier.1.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Define loss function and optimizer (only for the new parameters)\n",
        "criterion_tl = nn.CrossEntropyLoss()\n",
        "optimizer_tl = torch.optim.Adam(\n",
        "    filter(lambda p: p.requires_grad, model.parameters()),\n",
        "    lr=0.001\n",
        ")"
      ],
      "metadata": {
        "id": "nANDOtVMm8hW"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = train_loader\n",
        "test_dataloader = test_loader\n"
      ],
      "metadata": {
        "id": "xU4xJH-e2zfm"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_loader)\n"
      ],
      "metadata": {
        "id": "MZPCNw2a20ne",
        "outputId": "38abe3b3-8dd8-4e06-e25c-745f5f181e03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x788065499df0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),   # \n",
        "    transforms.Grayscale(num_output_channels=3),  #  3 channels\n",
        "    transforms.ToTensor(),\n",
        "])\n"
      ],
      "metadata": {
        "id": "LON7Fm9km8nZ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "weights = models.EfficientNet_B0_Weights.DEFAULT\n",
        "transform = weights.transforms()\n"
      ],
      "metadata": {
        "id": "QulOzVy03h0G"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"data/train\"\n",
        "test_dir = \"data/test\"\n"
      ],
      "metadata": {
        "id": "9H9nCMwC6TI_"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"/content/drive/MyDrive/data/train\"\n",
        "test_dir = \"/content/drive/MyDrive/data/test\"\n"
      ],
      "metadata": {
        "id": "AvhP7idq7Ecw"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training history\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(efficientnet_results['train_loss'], label='Train Loss')\n",
        "plt.plot(efficientnet_results['test_loss'], label='Test Loss')\n",
        "plt.title('EfficientNet Loss (Transfer Learning)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(efficientnet_results['train_acc'], label='Train Accuracy')\n",
        "plt.plot(efficientnet_results['test_acc'], label='Test Accuracy')\n",
        "plt.title('EfficientNet Accuracy (Transfer Learning)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v1FfE526nNl5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "outputId": "6c8eec09-b85d-4b79-d097-430c9a5f058a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'efficientnet_results' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1912626694.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mefficientnet_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mefficientnet_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Test Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'EfficientNet Loss (Transfer Learning)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'efficientnet_results' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAGyCAYAAADUEqJCAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAGxFJREFUeJzt3X9s1dX9x/FXW+gtRlpwXW9Ld7UD50+UYitdQWJc7myiqeOPxU4M7Rp/TO2McrMJFWhFlDKnpIkUiajTP3TFGTFGmjrtJEbtQiw00QkYLNrOeAud415WtIXe8/3DeP1WWuRTet+l5flI7h8cz+d+zj2p95nP7b29Sc45JwAAjCSP9QIAAGcWwgMAMEV4AACmCA8AwBThAQCYIjwAAFOEBwBgivAAAEwRHgCAKcIDADDlOTxvv/22SktLNWPGDCUlJemVV175wWO2b9+uK664Qj6fT+eff76effbZESwVADAReA5Pb2+v5syZo4aGhpOav3//fl1//fW65ppr1N7ernvvvVe33nqrXn/9dc+LBQCMf0mn8kdCk5KStHXrVi1atGjYOcuWLdO2bdv04Ycfxsd+85vf6NChQ2pubh7pqQEA49SkRJ+gtbVVwWBw0FhJSYnuvffeYY/p6+tTX19f/N+xWExffvmlfvSjHykpKSlRSwUAfI9zTocPH9aMGTOUnDw6bwtIeHjC4bD8fv+gMb/fr2g0qq+++kpTpkw57pi6ujqtXr060UsDAJykrq4u/eQnPxmV+0p4eEaiurpaoVAo/u9IJKJzzz1XXV1dSk9PH8OVAcCZJRqNKhAIaOrUqaN2nwkPT3Z2trq7uweNdXd3Kz09fcirHUny+Xzy+XzHjaenpxMeABgDo/lrjoR/jqe4uFgtLS2Dxt544w0VFxcn+tQAgNOQ5/D873//U3t7u9rb2yV983bp9vZ2dXZ2SvrmZbLy8vL4/DvuuEMdHR267777tGfPHm3cuFEvvviili5dOjqPAAAwrngOz/vvv6+5c+dq7ty5kqRQKKS5c+eqpqZGkvTFF1/EIyRJP/3pT7Vt2za98cYbmjNnjh577DE99dRTKikpGaWHAAAYT07pczxWotGoMjIyFIlE+B0PABhKxPMvf6sNAGCK8AAATBEeAIApwgMAMEV4AACmCA8AwBThAQCYIjwAAFOEBwBgivAAAEwRHgCAKcIDADBFeAAApggPAMAU4QEAmCI8AABThAcAYIrwAABMER4AgCnCAwAwRXgAAKYIDwDAFOEBAJgiPAAAU4QHAGCK8AAATBEeAIApwgMAMEV4AACmCA8AwBThAQCYIjwAAFOEBwBgivAAAEwRHgCAKcIDADBFeAAApggPAMAU4QEAmCI8AABThAcAYIrwAABMER4AgCnCAwAwRXgAAKYIDwDAFOEBAJgiPAAAU4QHAGCK8AAATBEeAIApwgMAMEV4AACmCA8AwBThAQCYIjwAAFOEBwBgivAAAEwRHgCAKcIDADBFeAAApggPAMAU4QEAmCI8AABThAcAYIrwAABMjSg8DQ0NysvLU1pamoqKirRjx44Tzq+vr9eFF16oKVOmKBAIaOnSpfr6669HtGAAwPjmOTxbtmxRKBRSbW2tdu7cqTlz5qikpEQHDhwYcv4LL7yg5cuXq7a2Vrt379bTTz+tLVu26P777z/lxQMAxh/P4Vm/fr1uu+02VVZW6pJLLtGmTZt01lln6Zlnnhly/nvvvacFCxZo8eLFysvL07XXXqubbrrpB6+SAAATk6fw9Pf3q62tTcFg8Ls7SE5WMBhUa2vrkMfMnz9fbW1t8dB0dHSoqalJ11133bDn6evrUzQaHXQDAEwMk7xM7unp0cDAgPx+/6Bxv9+vPXv2DHnM4sWL1dPTo6uuukrOOR07dkx33HHHCV9qq6ur0+rVq70sDQAwTiT8XW3bt2/X2rVrtXHjRu3cuVMvv/yytm3bpjVr1gx7THV1tSKRSPzW1dWV6GUCAIx4uuLJzMxUSkqKuru7B413d3crOzt7yGNWrVqlJUuW6NZbb5UkXXbZZert7dXtt9+uFStWKDn5+Pb5fD75fD4vSwMAjBOernhSU1NVUFCglpaW+FgsFlNLS4uKi4uHPObIkSPHxSUlJUWS5Jzzul4AwDjn6YpHkkKhkCoqKlRYWKh58+apvr5evb29qqyslCSVl5crNzdXdXV1kqTS0lKtX79ec+fOVVFRkfbt26dVq1aptLQ0HiAAwJnDc3jKysp08OBB1dTUKBwOKz8/X83NzfE3HHR2dg66wlm5cqWSkpK0cuVKff755/rxj3+s0tJSPfzww6P3KAAA40aSGwevd0WjUWVkZCgSiSg9PX2slwMAZ4xEPP/yt9oAAKYIDwDAFOEBAJgiPAAAU4QHAGCK8AAATBEeAIApwgMAMEV4AACmCA8AwBThAQCYIjwAAFOEBwBgivAAAEwRHgCAKcIDADBFeAAApggPAMAU4QEAmCI8AABThAcAYIrwAABMER4AgCnCAwAwRXgAAKYIDwDAFOEBAJgiPAAAU4QHAGCK8AAATBEeAIApwgMAMEV4AACmCA8AwBThAQCYIjwAAFOEBwBgivAAAEwRHgCAKcIDADBFeAAApggPAMAU4QEAmCI8AABThAcAYIrwAABMER4AgCnCAwAwRXgAAKYIDwDAFOEBAJgiPAAAU4QHAGCK8AAATBEeAIApwgMAMEV4AACmCA8AwBThAQCYIjwAAFOEBwBgivAAAEwRHgCAKcIDADBFeAAApggPAMDUiMLT0NCgvLw8paWlqaioSDt27Djh/EOHDqmqqko5OTny+Xy64IIL1NTUNKIFAwDGt0leD9iyZYtCoZA2bdqkoqIi1dfXq6SkRHv37lVWVtZx8/v7+/XLX/5SWVlZeumll5Sbm6vPPvtM06ZNG431AwDGmSTnnPNyQFFRka688kpt2LBBkhSLxRQIBHT33Xdr+fLlx83ftGmT/vznP2vPnj2aPHnyiBYZjUaVkZGhSCSi9PT0Ed0HAMC7RDz/enqprb+/X21tbQoGg9/dQXKygsGgWltbhzzm1VdfVXFxsaqqquT3+zV79mytXbtWAwMDw56nr69P0Wh00A0AMDF4Ck9PT48GBgbk9/sHjfv9foXD4SGP6ejo0EsvvaSBgQE1NTVp1apVeuyxx/TQQw8Ne566ujplZGTEb4FAwMsyAQCnsYS/qy0WiykrK0tPPvmkCgoKVFZWphUrVmjTpk3DHlNdXa1IJBK/dXV1JXqZAAAjnt5ckJmZqZSUFHV3dw8a7+7uVnZ29pDH5OTkaPLkyUpJSYmPXXzxxQqHw+rv71dqaupxx/h8Pvl8Pi9LAwCME56ueFJTU1VQUKCWlpb4WCwWU0tLi4qLi4c8ZsGCBdq3b59isVh87OOPP1ZOTs6Q0QEATGyeX2oLhULavHmznnvuOe3evVt33nmnent7VVlZKUkqLy9XdXV1fP6dd96pL7/8Uvfcc48+/vhjbdu2TWvXrlVVVdXoPQoAwLjh+XM8ZWVlOnjwoGpqahQOh5Wfn6/m5ub4Gw46OzuVnPxdzwKBgF5//XUtXbpUl19+uXJzc3XPPfdo2bJlo/coAADjhufP8YwFPscDAGNjzD/HAwDAqSI8AABThAcAYIrwAABMER4AgCnCAwAwRXgAAKYIDwDAFOEBAJgiPAAAU4QHAGCK8AAATBEeAIApwgMAMEV4AACmCA8AwBThAQCYIjwAAFOEBwBgivAAAEwRHgCAKcIDADBFeAAApggPAMAU4QEAmCI8AABThAcAYIrwAABMER4AgCnCAwAwRXgAAKYIDwDAFOEBAJgiPAAAU4QHAGCK8AAATBEeAIApwgMAMEV4AACmCA8AwBThAQCYIjwAAFOEBwBgivAAAEwRHgCAKcIDADBFeAAApggPAMAU4QEAmCI8AABThAcAYIrwAABMER4AgCnCAwAwRXgAAKYIDwDAFOEBAJgiPAAAU4QHAGCK8AAATBEeAIApwgMAMEV4AACmCA8AwBThAQCYIjwAAFMjCk9DQ4Py8vKUlpamoqIi7dix46SOa2xsVFJSkhYtWjSS0wIAJgDP4dmyZYtCoZBqa2u1c+dOzZkzRyUlJTpw4MAJj/v000/1hz/8QQsXLhzxYgEA45/n8Kxfv1633XabKisrdckll2jTpk0666yz9Mwzzwx7zMDAgG6++WatXr1aM2fOPKUFAwDGN0/h6e/vV1tbm4LB4Hd3kJysYDCo1tbWYY978MEHlZWVpVtuueWkztPX16doNDroBgCYGDyFp6enRwMDA/L7/YPG/X6/wuHwkMe88847evrpp7V58+aTPk9dXZ0yMjLit0Ag4GWZAIDTWELf1Xb48GEtWbJEmzdvVmZm5kkfV11drUgkEr91dXUlcJUAAEuTvEzOzMxUSkqKuru7B413d3crOzv7uPmffPKJPv30U5WWlsbHYrHYNyeeNEl79+7VrFmzjjvO5/PJ5/N5WRoAYJzwdMWTmpqqgoICtbS0xMdisZhaWlpUXFx83PyLLrpIH3zwgdrb2+O3G264Qddcc43a29t5CQ0AzkCerngkKRQKqaKiQoWFhZo3b57q6+vV29uryspKSVJ5eblyc3NVV1entLQ0zZ49e9Dx06ZNk6TjxgEAZwbP4SkrK9PBgwdVU1OjcDis/Px8NTc3x99w0NnZqeRk/iACAGBoSc45N9aL+CHRaFQZGRmKRCJKT08f6+UAwBkjEc+/XJoAAEwRHgCAKcIDADBFeAAApggPAMAU4QEAmCI8AABThAcAYIrwAABMER4AgCnCAwAwRXgAAKYIDwDAFOEBAJgiPAAAU4QHAGCK8AAATBEeAIApwgMAMEV4AACmCA8AwBThAQCYIjwAAFOEBwBgivAAAEwRHgCAKcIDADBFeAAApggPAMAU4QEAmCI8AABThAcAYIrwAABMER4AgCnCAwAwRXgAAKYIDwDAFOEBAJgiPAAAU4QHAGCK8AAATBEeAIApwgMAMEV4AACmCA8AwBThAQCYIjwAAFOEBwBgivAAAEwRHgCAKcIDADBFeAAApggPAMAU4QEAmCI8AABThAcAYIrwAABMER4AgCnCAwAwRXgAAKYIDwDAFOEBAJgiPAAAU4QHAGCK8AAATBEeAICpEYWnoaFBeXl5SktLU1FRkXbs2DHs3M2bN2vhwoWaPn26pk+frmAweML5AICJzXN4tmzZolAopNraWu3cuVNz5sxRSUmJDhw4MOT87du366abbtJbb72l1tZWBQIBXXvttfr8889PefEAgPEnyTnnvBxQVFSkK6+8Uhs2bJAkxWIxBQIB3X333Vq+fPkPHj8wMKDp06drw4YNKi8vP6lzRqNRZWRkKBKJKD093ctyAQCnIBHPv56uePr7+9XW1qZgMPjdHSQnKxgMqrW19aTu48iRIzp69KjOOeecYef09fUpGo0OugEAJgZP4enp6dHAwID8fv+gcb/fr3A4fFL3sWzZMs2YMWNQvL6vrq5OGRkZ8VsgEPCyTADAacz0XW3r1q1TY2Ojtm7dqrS0tGHnVVdXKxKJxG9dXV2GqwQAJNIkL5MzMzOVkpKi7u7uQePd3d3Kzs4+4bGPPvqo1q1bpzfffFOXX375Cef6fD75fD4vSwMAjBOernhSU1NVUFCglpaW+FgsFlNLS4uKi4uHPe6RRx7RmjVr1NzcrMLCwpGvFgAw7nm64pGkUCikiooKFRYWat68eaqvr1dvb68qKyslSeXl5crNzVVdXZ0k6U9/+pNqamr0wgsvKC8vL/67oLPPPltnn332KD4UAMB44Dk8ZWVlOnjwoGpqahQOh5Wfn6/m5ub4Gw46OzuVnPzdhdQTTzyh/v5+/frXvx50P7W1tXrggQdObfUAgHHH8+d4xgKf4wGAsTHmn+MBAOBUER4AgCnCAwAwRXgAAKYIDwDAFOEBAJgiPAAAU4QHAGCK8AAATBEeAIApwgMAMEV4AACmCA8AwBThAQCYIjwAAFOEBwBgivAAAEwRHgCAKcIDADBFeAAApggPAMAU4QEAmCI8AABThAcAYIrwAABMER4AgCnCAwAwRXgAAKYIDwDAFOEBAJgiPAAAU4QHAGCK8AAATBEeAIApwgMAMEV4AACmCA8AwBThAQCYIjwAAFOEBwBgivAAAEwRHgCAKcIDADBFeAAApggPAMAU4QEAmCI8AABThAcAYIrwAABMER4AgCnCAwAwRXgAAKYIDwDAFOEBAJgiPAAAU4QHAGCK8AAATBEeAIApwgMAMEV4AACmCA8AwBThAQCYIjwAAFOEBwBgivAAAEwRHgCAqRGFp6GhQXl5eUpLS1NRUZF27Nhxwvl/+9vfdNFFFyktLU2XXXaZmpqaRrRYAMD45zk8W7ZsUSgUUm1trXbu3Kk5c+aopKREBw4cGHL+e++9p5tuukm33HKLdu3apUWLFmnRokX68MMPT3nxAIDxJ8k557wcUFRUpCuvvFIbNmyQJMViMQUCAd19991avnz5cfPLysrU29ur1157LT7285//XPn5+dq0adNJnTMajSojI0ORSETp6elelgsAOAWJeP6d5GVyf3+/2traVF1dHR9LTk5WMBhUa2vrkMe0trYqFAoNGispKdErr7wy7Hn6+vrU19cX/3ckEpH0zQYAAOx8+7zr8RrlhDyFp6enRwMDA/L7/YPG/X6/9uzZM+Qx4XB4yPnhcHjY89TV1Wn16tXHjQcCAS/LBQCMkv/85z/KyMgYlfvyFB4r1dXVg66SDh06pPPOO0+dnZ2j9sAngmg0qkAgoK6uLl6C/B72Zmjsy/DYm6FFIhGde+65Ouecc0btPj2FJzMzUykpKeru7h403t3drezs7CGPyc7O9jRfknw+n3w+33HjGRkZ/EAMIT09nX0ZBnszNPZleOzN0JKTR+/TN57uKTU1VQUFBWppaYmPxWIxtbS0qLi4eMhjiouLB82XpDfeeGPY+QCAic3zS22hUEgVFRUqLCzUvHnzVF9fr97eXlVWVkqSysvLlZubq7q6OknSPffco6uvvlqPPfaYrr/+ejU2Nur999/Xk08+ObqPBAAwLngOT1lZmQ4ePKiamhqFw2Hl5+erubk5/gaCzs7OQZdk8+fP1wsvvKCVK1fq/vvv189+9jO98sormj179kmf0+fzqba2dsiX385k7Mvw2JuhsS/DY2+Gloh98fw5HgAATgV/qw0AYIrwAABMER4AgCnCAwAwddqEh69aGJqXfdm8ebMWLlyo6dOna/r06QoGgz+4j+OZ15+ZbzU2NiopKUmLFi1K7ALHiNd9OXTokKqqqpSTkyOfz6cLLrhgQv7/5HVf6uvrdeGFF2rKlCkKBAJaunSpvv76a6PV2nn77bdVWlqqGTNmKCkp6YR/R/Nb27dv1xVXXCGfz6fzzz9fzz77rLeTutNAY2OjS01Ndc8884z717/+5W677TY3bdo0193dPeT8d99916WkpLhHHnnEffTRR27lypVu8uTJ7oMPPjBeeWJ53ZfFixe7hoYGt2vXLrd7927329/+1mVkZLh///vfxitPPK978639+/e73Nxct3DhQverX/3KZrGGvO5LX1+fKywsdNddd51755133P79+9327dtde3u78coTy+u+PP/8887n87nnn3/e7d+/373++usuJyfHLV261HjlidfU1ORWrFjhXn75ZSfJbd269YTzOzo63FlnneVCoZD76KOP3OOPP+5SUlJcc3PzSZ/ztAjPvHnzXFVVVfzfAwMDbsaMGa6urm7I+TfeeKO7/vrrB40VFRW53/3udwldpzWv+/J9x44dc1OnTnXPPfdcopY4ZkayN8eOHXPz5893Tz31lKuoqJiQ4fG6L0888YSbOXOm6+/vt1rimPC6L1VVVe4Xv/jFoLFQKOQWLFiQ0HWOtZMJz3333ecuvfTSQWNlZWWupKTkpM8z5i+1fftVC8FgMD52Ml+18P/nS9981cJw88ejkezL9x05ckRHjx4d1T/udzoY6d48+OCDysrK0i233GKxTHMj2ZdXX31VxcXFqqqqkt/v1+zZs7V27VoNDAxYLTvhRrIv8+fPV1tbW/zluI6ODjU1Nem6664zWfPpbDSef8f8r1NbfdXCeDOSffm+ZcuWacaMGcf9kIx3I9mbd955R08//bTa29sNVjg2RrIvHR0d+sc//qGbb75ZTU1N2rdvn+666y4dPXpUtbW1FstOuJHsy+LFi9XT06OrrrpKzjkdO3ZMd9xxh+6//36LJZ/Whnv+jUaj+uqrrzRlypQfvI8xv+JBYqxbt06NjY3aunWr0tLSxno5Y+rw4cNasmSJNm/erMzMzLFezmklFospKytLTz75pAoKClRWVqYVK1ac9LcDT1Tbt2/X2rVrtXHjRu3cuVMvv/yytm3bpjVr1oz10iaEMb/isfqqhfFmJPvyrUcffVTr1q3Tm2++qcsvvzyRyxwTXvfmk08+0aeffqrS0tL4WCwWkyRNmjRJe/fu1axZsxK7aAMj+ZnJycnR5MmTlZKSEh+7+OKLFQ6H1d/fr9TU1ISu2cJI9mXVqlVasmSJbr31VknSZZddpt7eXt1+++1asWLFqH5FwHgz3PNvenr6SV3tSKfBFQ9ftTC0keyLJD3yyCNas2aNmpubVVhYaLFUc1735qKLLtIHH3yg9vb2+O2GG27QNddco/b29gnzzbYj+ZlZsGCB9u3bFw+xJH388cfKycmZENGRRrYvR44cOS4u38bZneF/3nJUnn+9v+9h9DU2Njqfz+eeffZZ99FHH7nbb7/dTZs2zYXDYeecc0uWLHHLly+Pz3/33XfdpEmT3KOPPup2797tamtrJ+zbqb3sy7p161xqaqp76aWX3BdffBG/HT58eKweQsJ43Zvvm6jvavO6L52dnW7q1Knu97//vdu7d6977bXXXFZWlnvooYfG6iEkhNd9qa2tdVOnTnV//etfXUdHh/v73//uZs2a5W688caxeggJc/jwYbdr1y63a9cuJ8mtX7/e7dq1y3322WfOOeeWL1/ulixZEp//7dup//jHP7rdu3e7hoaG8fl2auece/zxx925557rUlNT3bx589w///nP+H+7+uqrXUVFxaD5L774orvgggtcamqqu/TSS922bduMV2zDy76cd955TtJxt9raWvuFG/D6M/P/TdTwOOd9X9577z1XVFTkfD6fmzlzpnv44YfdsWPHjFedeF725ejRo+6BBx5ws2bNcmlpaS4QCLi77rrL/fe//7VfeIK99dZbQz5vfLsfFRUV7uqrrz7umPz8fJeamupmzpzp/vKXv3g6J1+LAAAwNea/4wEAnFkIDwDAFOEBAJgiPAAAU4QHAGCK8AAATBEeAIApwgMAMEV4AACmCA8AwBThAQCYIjwAAFP/B0FgvZXqBEXnAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Questions for Part 2:\n",
        "1.  Compare the performance of the LeNet model (from Part 1) with the transfer learning model (EfficientNet_B0). Which one performed better and why do you think that is?\n",
        "    *   **Your Answer:** = EfficientNet_B0 (Transfer Learning)  LeNet LeNet   (random weights)  dataset  \n",
        "\n",
        "2.  Explain the concept of \"freezing\" layers in transfer learning. Why is it done, and what are its benefits?\n",
        "    *   **Your Answer:** = \n",
        "\n",
        "\n",
        "3.  What challenges might arise when using transfer learning on a dataset that is significantly different from the dataset the pre-trained model was originally trained on (e.g., medical images vs. ImageNet)?\n",
        "    *   **Your Answer:** = dataset  dataset  pre-train  (  ImageNet)  :  featureImageNet \n",
        "    Domain shift \n",
        "\n",
        "\n",
        " feature \n",
        "\n",
        " Fine-tune\n",
        " unfreeze layer   \n",
        "\n",
        "\n",
        "4.  Choose 3 images from the test set. Display the images and show their predicted classes."
      ],
      "metadata": {
        "id": "8gyxRyRHfcOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "efficientnet_model.eval()  #  evaluation mode\n",
        "\n",
        "x = torch.rand(1, 3, 224, 224).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    prediction = efficientnet_model(x)\n",
        "\n",
        "pred_class = torch.argmax(prediction, dim=1)\n",
        "\n",
        "print(\"Predicted class index:\", pred_class.item())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "No6lZcHCg_Ny",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36903209-5365-4c3c-ebac-8e8a8d8ae789"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class index: 21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$ P(y=0 | x) = \\frac{e^{0.1164}}{e^{0.1164} + e^{-0.0953} + e^{0.0978}}. $$\n",
        "\n",
        "$$ P(y=1 | x) = \\frac{e^{-0.0953}}{e^{0.1164} + e^{-0.0953} + e^{0.0978}}. $$\n",
        "\n",
        "$$ P(y=2 | x) = \\frac{e^{0.0978}}{e^{0.1164} + e^{-0.0953} + e^{0.0978}}. $$"
      ],
      "metadata": {
        "id": "JRyKAexKlWCd"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}